{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-12T16:23:07.019184Z",
     "start_time": "2025-06-12T16:23:02.942089Z"
    }
   },
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-12T16:23:09.126147Z",
     "start_time": "2025-06-12T16:23:09.123818Z"
    }
   },
   "cell_type": "code",
   "source": [
    "MODEL_CONFIGS = {\n",
    "    \"lightweight\": \"all-MiniLM-L6-v2\",      # 22M params, 384d\n",
    "    \"performance\": \"BAAI/bge-large-en-v1.5\"  # 335M params, 1024d\n",
    "}"
   ],
   "id": "9f30adba0edf750f",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-12T16:23:09.910015Z",
     "start_time": "2025-06-12T16:23:09.907226Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_device(device: str = \"auto\") -> str:\n",
    "    \"\"\"Determine optimal device for computation.\"\"\"\n",
    "    if device == \"auto\":\n",
    "        if torch.cuda.is_available():\n",
    "            return \"cuda\"\n",
    "        elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n",
    "            return \"mps\"  # Apple Silicon GPU\n",
    "        else:\n",
    "            return \"cpu\"\n",
    "    return device"
   ],
   "id": "5b68340c32038fdd",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-12T16:23:29.842783Z",
     "start_time": "2025-06-12T16:23:29.840410Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def setup_model(model_tier: str = \"lightweight\", device: str = \"auto\") -> SentenceTransformer:\n",
    "    \"\"\"Load and return the sentence transformer model.\"\"\"\n",
    "    device = get_device(device)\n",
    "    model_name = MODEL_CONFIGS[model_tier]\n",
    "\n",
    "    print(f\"Loading {model_name} on {device}...\")\n",
    "    model = SentenceTransformer(model_name, device=device)\n",
    "    print(f\"Model loaded. Embedding dimension: {model.get_sentence_embedding_dimension()}\")\n",
    "\n",
    "    return model"
   ],
   "id": "ed28fdca29802673",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-12T16:23:35.156551Z",
     "start_time": "2025-06-12T16:23:35.153963Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load_json_data(json_path: str) -> List[Dict]:\n",
    "    \"\"\"Load and validate JSON token data.\"\"\"\n",
    "    with open(json_path, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    # Extract tokens if nested in structure\n",
    "    tokens = data['tokens'] if 'tokens' in data else data\n",
    "    print(f\"Loaded {len(tokens)} tokens from {json_path}\")\n",
    "\n",
    "    return tokens"
   ],
   "id": "a15ff5b31e2aa30a",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-12T16:23:55.065357Z",
     "start_time": "2025-06-12T16:23:55.060438Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def extract_label_features(tokens: List[Dict]) -> Tuple[np.ndarray, List[str], Dict]:\n",
    "    \"\"\"\n",
    "    Extract and encode label features from tokens.\n",
    "\n",
    "    Returns:\n",
    "        label_features: Standardized feature matrix\n",
    "        feature_names: Names of features\n",
    "        encoders: Dict of label encoders for later use\n",
    "    \"\"\"\n",
    "    # Collect all label types and values\n",
    "    all_labels = {}\n",
    "    for token in tokens:\n",
    "        for label_type, label_info in token['labels'].items():\n",
    "            if label_type not in all_labels:\n",
    "                all_labels[label_type] = set()\n",
    "            all_labels[label_type].add(label_info['value'])\n",
    "\n",
    "    # Create label encoders for categorical variables\n",
    "    label_encoders = {}\n",
    "    for label_type, values in all_labels.items():\n",
    "        if 'null' in values or len(values) > 10:  # Categorical encoding\n",
    "            label_encoders[label_type] = LabelEncoder()\n",
    "            label_encoders[label_type].fit(list(values))\n",
    "\n",
    "    # Extract features for each token\n",
    "    label_data = []\n",
    "    for token in tokens:\n",
    "        token_features = []\n",
    "        for label_type, label_info in token['labels'].items():\n",
    "            value = label_info['value']\n",
    "            confidence = label_info['confidence']\n",
    "\n",
    "            if label_type in label_encoders:\n",
    "                # Categorical: encode and weight by confidence\n",
    "                encoded_val = label_encoders[label_type].transform([value])[0]\n",
    "                token_features.extend([encoded_val * confidence, confidence])\n",
    "            else:\n",
    "                # Numerical or string hash\n",
    "                try:\n",
    "                    num_val = float(value) if value != 'null' else 0.0\n",
    "                    token_features.extend([num_val * confidence, confidence])\n",
    "                except ValueError:\n",
    "                    # String hash as feature\n",
    "                    hash_val = hash(value) % 1000\n",
    "                    token_features.extend([hash_val * confidence, confidence])\n",
    "\n",
    "        label_data.append(token_features)\n",
    "\n",
    "    # Convert to numpy and standardize\n",
    "    label_features = np.array(label_data)\n",
    "    scaler = StandardScaler()\n",
    "    if label_features.size > 0:\n",
    "        label_features = scaler.fit_transform(label_features)\n",
    "\n",
    "    # Generate feature names\n",
    "    feature_names = []\n",
    "    for label_type in sorted(all_labels.keys()):\n",
    "        feature_names.extend([f\"{label_type}_value\", f\"{label_type}_confidence\"])\n",
    "\n",
    "    print(f\"Extracted {len(feature_names)} label features\")\n",
    "\n",
    "    return label_features, feature_names, label_encoders"
   ],
   "id": "4c38f197a2387fca",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-12T16:23:58.683766Z",
     "start_time": "2025-06-12T16:23:58.681689Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def extract_texts(tokens: List[Dict]) -> List[str]:\n",
    "    \"\"\"Extract text content from tokens.\"\"\"\n",
    "    return [token['token'] for token in tokens]"
   ],
   "id": "fe1a3f128bbdecc2",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-12T16:24:25.267782Z",
     "start_time": "2025-06-12T16:24:25.265131Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_semantic_embeddings(model: SentenceTransformer, texts: List[str]) -> np.ndarray:\n",
    "    \"\"\"Generate semantic embeddings from text.\"\"\"\n",
    "    print(\"Generating semantic embeddings...\")\n",
    "    embeddings = model.encode(\n",
    "        texts,\n",
    "        show_progress_bar=True,\n",
    "        convert_to_numpy=True,\n",
    "        normalize_embeddings=True\n",
    "    )\n",
    "    print(f\"Semantic embeddings shape: {embeddings.shape}\")\n",
    "    return embeddings"
   ],
   "id": "153d6675e3064a91",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-12T16:24:27.313629Z",
     "start_time": "2025-06-12T16:24:27.311300Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def combine_embeddings(semantic_embeddings: np.ndarray,\n",
    "                       label_features: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Combine semantic embeddings with label features.\"\"\"\n",
    "    if label_features.size > 0:\n",
    "        print(\"Combining semantic and label features...\")\n",
    "        combined = np.concatenate([semantic_embeddings, label_features], axis=1)\n",
    "    else:\n",
    "        combined = semantic_embeddings\n",
    "\n",
    "    print(f\"Final embedding shape: {combined.shape}\")\n",
    "    return combined"
   ],
   "id": "2e8758ad829d5c87",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-12T16:24:28.119754Z",
     "start_time": "2025-06-12T16:24:28.115718Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def save_embeddings(embeddings: np.ndarray,\n",
    "                    texts: List[str],\n",
    "                    feature_names: List[str],\n",
    "                    model_tier: str,\n",
    "                    output_dir: str = \"embeddings_output\") -> Dict[str, str]:\n",
    "    \"\"\"Save embeddings and metadata to files.\"\"\"\n",
    "    output_path = Path(output_dir) / model_tier\n",
    "    output_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Save embeddings\n",
    "    embedding_file = output_path / f\"embeddings_{model_tier}.npy\"\n",
    "    np.save(embedding_file, embeddings)\n",
    "\n",
    "    # Save metadata\n",
    "    metadata = {\n",
    "        'model_tier': model_tier,\n",
    "        'model_name': MODEL_CONFIGS[model_tier],\n",
    "        'embedding_dim': embeddings.shape[1],\n",
    "        'label_features': len(feature_names),\n",
    "        'num_tokens': len(texts),\n",
    "        'feature_names': feature_names\n",
    "    }\n",
    "\n",
    "    metadata_file = output_path / f\"metadata_{model_tier}.json\"\n",
    "    with open(metadata_file, 'w') as f:\n",
    "        json.dump(metadata, f, indent=2)\n",
    "\n",
    "    # Save token mapping\n",
    "    token_df = pd.DataFrame({\n",
    "        'index': range(len(texts)),\n",
    "        'token': texts,\n",
    "        'embedding_file': str(embedding_file)\n",
    "    })\n",
    "    token_file = output_path / f\"token_mapping_{model_tier}.csv\"\n",
    "    token_df.to_csv(token_file, index=False)\n",
    "\n",
    "    file_paths = {\n",
    "        'embeddings': str(embedding_file),\n",
    "        'metadata': str(metadata_file),\n",
    "        'token_mapping': str(token_file)\n",
    "    }\n",
    "\n",
    "    print(f\"Saved embeddings to {embedding_file}\")\n",
    "    print(f\"Saved metadata to {metadata_file}\")\n",
    "    print(f\"Saved token mapping to {token_file}\")\n",
    "\n",
    "    return file_paths"
   ],
   "id": "41350e2c47a17482",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-12T16:24:30.438733Z",
     "start_time": "2025-06-12T16:24:30.436102Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load_saved_embeddings(embedding_file: str) -> np.ndarray:\n",
    "    \"\"\"Load previously saved embeddings.\"\"\"\n",
    "    return np.load(embedding_file)"
   ],
   "id": "828762df47966854",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-12T16:24:31.172186Z",
     "start_time": "2025-06-12T16:24:31.169580Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_embedding_stats(embeddings: np.ndarray) -> Dict:\n",
    "    \"\"\"Get basic statistics about embeddings.\"\"\"\n",
    "    return {\n",
    "        'shape': embeddings.shape,\n",
    "        'mean': embeddings.mean(),\n",
    "        'std': embeddings.std(),\n",
    "        'min': embeddings.min(),\n",
    "        'max': embeddings.max(),\n",
    "        'memory_mb': embeddings.nbytes / (1024 * 1024)}"
   ],
   "id": "c85e61f1926272d4",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-12T16:24:40.650548Z",
     "start_time": "2025-06-12T16:24:40.647484Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Quick workflow functions for common operations\n",
    "def create_full_embeddings(json_path: str,\n",
    "                           model_tier: str = \"lightweight\",\n",
    "                           output_dir: str = \"embeddings_output\") -> Tuple[np.ndarray, Dict[str, str]]:\n",
    "    \"\"\"Complete workflow: JSON -> embeddings -> saved files.\"\"\"\n",
    "\n",
    "    # Load data\n",
    "    tokens = load_json_data(json_path)\n",
    "    texts = extract_texts(tokens)\n",
    "\n",
    "    # Setup model\n",
    "    model = setup_model(model_tier)\n",
    "\n",
    "    # Extract features\n",
    "    label_features, feature_names, _ = extract_label_features(tokens)\n",
    "\n",
    "    # Create embeddings\n",
    "    semantic_embeddings = create_semantic_embeddings(model, texts)\n",
    "    final_embeddings = combine_embeddings(semantic_embeddings, label_features)\n",
    "\n",
    "    # Save results\n",
    "    file_paths = save_embeddings(\n",
    "        final_embeddings, texts, feature_names, model_tier, output_dir\n",
    "    )\n",
    "\n",
    "    return final_embeddings, file_paths"
   ],
   "id": "94598927b47422b3",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-12T16:24:41.906747Z",
     "start_time": "2025-06-12T16:24:41.904168Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def compare_model_tiers(json_path: str, output_dir: str = \"embeddings_output\"):\n",
    "    \"\"\"Generate embeddings with both model tiers for comparison.\"\"\"\n",
    "\n",
    "    print(\"=== Lightweight Model ===\")\n",
    "    embeddings_light, files_light = create_full_embeddings(\n",
    "        json_path, \"lightweight\", output_dir\n",
    "    )\n",
    "\n",
    "    print(f\"\\nLightweight stats: {get_embedding_stats(embeddings_light)}\")\n",
    "\n",
    "    print(\"\\n=== Performance Model ===\")\n",
    "    embeddings_perf, files_perf = create_full_embeddings(\n",
    "        json_path, \"performance\", output_dir\n",
    "    )\n",
    "\n",
    "    print(f\"\\nPerformance stats: {get_embedding_stats(embeddings_perf)}\")\n",
    "\n",
    "    return {\n",
    "        'lightweight': {'embeddings': embeddings_light, 'files': files_light},\n",
    "        'performance': {'embeddings': embeddings_perf, 'files': files_perf}\n",
    "    }"
   ],
   "id": "a26d1b2d7c3c630c",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-12T16:30:49.922428Z",
     "start_time": "2025-06-12T16:25:13.024005Z"
    }
   },
   "cell_type": "code",
   "source": "create_full_embeddings(\"./output.json\")",
   "id": "cf76542495568286",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1182 tokens from ./output.json\n",
      "Loading all-MiniLM-L6-v2 on mps...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5d792cc8217840e78d3520b48b03a010"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3b5a213b39434485840a5584fb611bb3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "README.md:   0%|          | 0.00/10.5k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9be0befa06e74a62836de0b0eb9dc0ea"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a9c8dec7f7e6453b96f70976e6f12623"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5d8bf45369b54ca5bc33da64db31502b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "05a29d8dbe1740288dff79e58166ab05"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "23aa375126434bc888c37f8beb671452"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e43807241a3047cd8127b6adb00198a7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c9519604cebc41918d863ba4f1cb86e0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "27916b01769f496c9381a01ab6fc432c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d13c56a17ec34966b52b0b1e27d64168"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded. Embedding dimension: 384\n",
      "Extracted 8 label features\n",
      "Generating semantic embeddings...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Batches:   0%|          | 0/37 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "58b70c6342c348eda723fadb33d6b709"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Semantic embeddings shape: (1182, 384)\n",
      "Combining semantic and label features...\n",
      "Final embedding shape: (1182, 392)\n",
      "Saved embeddings to embeddings_output/lightweight/embeddings_lightweight.npy\n",
      "Saved metadata to embeddings_output/lightweight/metadata_lightweight.json\n",
      "Saved token mapping to embeddings_output/lightweight/token_mapping_lightweight.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[-0.06433426,  0.049358  ,  0.0284998 , ...,  1.00532391,\n",
       "         -0.75986787,  0.59055148],\n",
       "        [-0.04567493,  0.00633722,  0.00670272, ..., -1.17343088,\n",
       "         -0.75986787,  0.59055148],\n",
       "        [-0.04477897,  0.07996801, -0.00450986, ..., -1.17343088,\n",
       "         -0.79263576,  0.3787057 ],\n",
       "        ...,\n",
       "        [-0.01809768, -0.02533447, -0.01309905, ...,  1.00532391,\n",
       "          1.0669421 ,  1.01424304],\n",
       "        [-0.10999466,  0.1284283 , -0.01778519, ..., -1.17343088,\n",
       "         -1.022011  , -1.10421477],\n",
       "        [-0.0313945 , -0.09264886,  0.04959343, ...,  1.00532391,\n",
       "          1.0669421 ,  1.01424304]], shape=(1182, 392)),\n",
       " {'embeddings': 'embeddings_output/lightweight/embeddings_lightweight.npy',\n",
       "  'metadata': 'embeddings_output/lightweight/metadata_lightweight.json',\n",
       "  'token_mapping': 'embeddings_output/lightweight/token_mapping_lightweight.csv'})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "d6ebd200113d7d58"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
